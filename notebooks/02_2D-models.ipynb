{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import tomllib\n",
    "\n",
    "from mads_hackathon import datasets, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, go to the `config.toml` file and change the `dev` value to your name. Please use `firstname_lastname` format. \n",
    "In addition to that, change the `port` value to the port of your team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using http://145.38.195.42:5002 as mlfow uri\n",
      "Using alex as dev name\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configfile = Path(\"config.toml\")\n",
    "with configfile.open(\"rb\") as f:\n",
    "    tomlconfig = tomllib.load(f)\n",
    "\n",
    "assert tomlconfig[\"dev\"] != \"dev\", ValueError(\"Please set dev in config.toml to your own name\")\n",
    "assert tomlconfig[\"port\"] != \"none\", ValueError(\"Please set port in config.toml to your own port\")\n",
    "uri = tomlconfig[\"mlflow_uri\"] + \":\" + tomlconfig[\"port\"]\n",
    "dev = tomlconfig[\"dev\"]\n",
    "print(f\"Using {uri} as mlfow uri\")\n",
    "print(f\"Using {dev} as dev name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = Path('../hackathon-data/')\n",
    "trainfile = (datadir / \"heart_big_train.parq\").resolve()\n",
    "validfile = (datadir / \"heart_big_valid.parq\").resolve()\n",
    "trainfile.exists(), validfile.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the backend, if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the 1D data into a 2D matrix with the HeartDataset2D class. See `src/mads_hackathon/datasets.py` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1, 5, 48]' is invalid for input of size 16810368",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m matrixshape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m48\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m traindataset \u001b[38;5;241m=\u001b[39m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHeartDataset2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmatrixshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m testdataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mHeartDataset2D(validfile, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape\u001b[38;5;241m=\u001b[39mmatrixshape)\n\u001b[1;32m      4\u001b[0m traindataset\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Desktop/advancedai/hackathon/group_c/src/mads_hackathon/datasets.py:135\u001b[0m, in \u001b[0;36mHeartDataset2D.__init__\u001b[0;34m(self, path, target, shape)\u001b[0m\n\u001b[1;32m    130\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(_x\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# original length is 187, which only allows for 11x17 2D tensors\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# 3*2**6 = 192. This makes it easier to reshape the data\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m# it also makes convolutions / maxpooling more predictable\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(y\u001b[38;5;241m.\u001b[39mvalues, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 5, 48]' is invalid for input of size 16810368"
     ]
    }
   ],
   "source": [
    "matrixshape = (3, 48)\n",
    "traindataset = datasets.HeartDataset2D(trainfile, target=\"target\", shape=matrixshape)\n",
    "testdataset = datasets.HeartDataset2D(validfile, target=\"target\", shape=matrixshape)\n",
    "traindataset.to(device)\n",
    "testdataset.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how that works. \n",
    "Compare this to the 1D data from notebook `01_explore-heart.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x, y \u001b[38;5;241m=\u001b[39m traindataset[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Assuming your tensor is named 'tensor'\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m viz \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(viz, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrainbow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m x\u001b[38;5;241m.\u001b[39mshape, y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "x, y = traindataset[0]\n",
    "# Assuming your tensor is named 'tensor'\n",
    "viz = x.squeeze().cpu().numpy()\n",
    "sns.heatmap(viz, cmap='rainbow')\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the config, then load into a streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNConfig(matrixshape=(4, 48), batchsize=64, input_channels=1, hidden=16, kernel_size=3, maxpool=2, num_layers=1, num_classes=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mads_hackathon.models import CNNConfig as Config\n",
    "\n",
    "config = Config(\n",
    "    matrixshape = (4,48),\n",
    "    batchsize = 64,\n",
    "    input_channels = 1,\n",
    "    hidden = 16,\n",
    "    kernel_size = 3,\n",
    "    maxpool = 2,\n",
    "    num_layers = 1,\n",
    "    num_classes = 5,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 171)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=config.batchsize)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=config.batchsize)\n",
    "len(trainstreamer), len(teststreamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 4, 48]), torch.Size([64]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer.stream())\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the CNN model. It uses a ConvBlock class that is a wrapper around a Conv2D and ReLU stack.\n",
    "The ConvBlock makes it easier to stack block in the CNN model, see `src/mads_hackathon/models.py` for the implementation.\n",
    "\n",
    "This is just a initial setup: please experiment with other architectures like:\n",
    "- adding ideas like resnet, googlenet, squeeze-excite, etc.\n",
    "- add additional layers like dropout, batchnorm, etc.\n",
    "- experiment with different ways to go from 4D to 2D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 48\n",
      "Caluclated flatten size: 768\n"
     ]
    }
   ],
   "source": [
    "from mads_hackathon.models import CNN\n",
    "model = CNN(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [64, 5]                   --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─ConvBlock: 2-1                    [64, 16, 4, 48]           --\n",
       "│    │    └─Sequential: 3-1              [64, 16, 4, 48]           2,480\n",
       "│    └─ConvBlock: 2-2                    [64, 16, 4, 48]           --\n",
       "│    │    └─Sequential: 3-2              [64, 16, 4, 48]           4,640\n",
       "│    └─ReLU: 2-3                         [64, 16, 4, 48]           --\n",
       "│    └─MaxPool2d: 2-4                    [64, 16, 2, 24]           --\n",
       "├─Sequential: 1-2                        [64, 5]                   --\n",
       "│    └─Flatten: 2-5                      [64, 768]                 --\n",
       "│    └─Linear: 2-6                       [64, 16]                  12,304\n",
       "│    └─ReLU: 2-7                         [64, 16]                  --\n",
       "│    └─Linear: 2-8                       [64, 5]                   85\n",
       "==========================================================================================\n",
       "Total params: 19,509\n",
       "Trainable params: 19,509\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 88.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 6.30\n",
       "Params size (MB): 0.08\n",
       "Estimated Total Size (MB): 6.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(config.batchsize, 1, *config.matrixshape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test if the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is unbalanced, so we are interested in much more than just accuracy.\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html for more information on the F1 micro/macro score.\n",
    "See `src/mads_hackathon/metrics.py` for the implementation. You might want to add more metrics, or change the settings for `average`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1scoremicro\n"
     ]
    }
   ],
   "source": [
    "f1micro = metrics.F1Score(average='micro')\n",
    "f1macro = metrics.F1Score(average='macro')\n",
    "precision = metrics.Precision(average='macro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "print(f1micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want a confusion matrix to see how the model is performing on the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_hackathon.metrics import caluclate_cfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the mlflow server to log the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/25 12:37:25 INFO mlflow.tracking.fluent: Experiment with name 'test1-alex' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/703179046667895742', creation_time=1732534645878, experiment_id='703179046667895742', last_update_time=1732534645878, lifecycle_stage='active', name='test1-alex', tags={}>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri)\n",
    "mlflow.set_experiment(\"test1-alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNConfig(matrixshape=(4, 48), batchsize=64, input_channels=1, hidden=16, kernel_size=3, maxpool=2, num_layers=1, num_classes=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(\n",
    "    matrixshape = (4,48),\n",
    "    batchsize = 64,\n",
    "    input_channels = 1,\n",
    "    hidden = 16,\n",
    "    kernel_size = 3,\n",
    "    maxpool = 2,\n",
    "    num_layers = 1,\n",
    "    num_classes = 5,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please dont just run the cell below, but walk trough what is being logged.\n",
    "For example, you might want to change the tag for the model and the dataset if you make changes there, and \n",
    "to the scheduler/earlystop if you are using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.2081,  39.3855,  15.1268, 136.5897,  13.6144]),\n",
       " tensor([0.0121, 0.3939, 0.1513, 1.3659, 0.1361]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_df = pd.read_parquet(trainfile)\n",
    "train_percentages = train_df.target.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "weights1 = torch.tensor((100 / train_percentages).to_numpy()).float().to(device)\n",
    "weights2 = torch.tensor((1 / train_percentages).to_numpy()).float().to(device)\n",
    "\n",
    "weights1, weights2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-25 12:39:16.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /Users/alex/Desktop/advancedai/hackathon/group_c/notebooks/logs/heart2D\u001b[0m\n",
      "\u001b[32m2024-11-25 12:39:16.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to logs/heart2D/20241125-123916\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/1368 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run wise-jay-164 at: http://145.38.195.42:5002/#/experiments/703179046667895742/runs/4f6fcde442fb4f2f84d97b42a345a8f0\n",
      "🧪 View experiment at: http://145.38.195.42:5002/#/experiments/703179046667895742\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 43\u001b[0m\n\u001b[1;32m     31\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(settings\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m     33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     35\u001b[0m     settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m cfm \u001b[38;5;241m=\u001b[39m caluclate_cfm(model, teststreamer)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39mdiag(cfm)):\n",
      "File \u001b[0;32m~/Desktop/advancedai/hackathon/group_c/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:90\u001b[0m, in \u001b[0;36mTrainer.loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mepochs), colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1e4706\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m         metric_dict, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalbatches()\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(epoch, train_loss, test_loss, metric_dict)\n",
      "File \u001b[0;32m~/Desktop/advancedai/hackathon/group_c/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.trainbatches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 124\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m train_steps\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "from dataclasses import asdict\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights1)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    optimizer = torch.optim.Adam\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=5,\n",
    "        metrics=[accuracy, f1micro, f1macro, precision, recall],\n",
    "        logdir=\"logs/heart2D\",\n",
    "        train_steps=len(trainstreamer),\n",
    "        valid_steps=len(teststreamer),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs=None,\n",
    "        earlystop_kwargs=None\n",
    "    )\n",
    "\n",
    "    # modify the tags when you change them!\n",
    "    mlflow.set_tag(\"model\", \"CNN\")\n",
    "    mlflow.set_tag(\"dataset\", \"heart2D\")\n",
    "    mlflow.set_tag(\"dev\", dev)\n",
    "    mlflow.log_param(\"scheduler\", \"None\")\n",
    "    mlflow.log_param(\"earlystop\", \"None\")\n",
    "\n",
    "    mlflow.log_params(asdict(config))\n",
    "    mlflow.log_param(\"epochs\", settings.epochs)\n",
    "    mlflow.log_param(\"matrix0\", config.matrixshape[0])\n",
    "    mlflow.log_param(\"matrix1\", config.matrixshape[1])\n",
    "    mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "    mlflow.log_params(settings.optimizer_kwargs)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=None,\n",
    "        device=device,\n",
    "        )\n",
    "    trainer.loop()\n",
    "    cfm = caluclate_cfm(model, teststreamer)\n",
    "    for i, tp in enumerate(np.diag(cfm)):\n",
    "        mlflow.log_metric(f\"TP_{i}\", tp)\n",
    "\n",
    "plot = sns.heatmap(cfm, annot=cfm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that, while the TP score for class 0 does get high without much effort, the challenge here will be in the other classes that lag behind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

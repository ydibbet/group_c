{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/svelthuis/.rye/py/cpython@3.11.10/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/svelthuis/.rye/py/cpython@3.11.10/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/svelthuis/.rye/py/cpython@3.11.10/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_759513/3142497349.py\", line 2, in <module>\n",
      "    from mltrainer.preprocessors import BasePreprocessor\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/mltrainer/__init__.py\", line 2, in <module>\n",
      "    from mltrainer.trainer import Trainer\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/mltrainer/trainer.py\", line 10, in <module>\n",
      "    import torch\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/home/svelthuis/group_c/.venv/lib/python3.11/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "from mltrainer.preprocessors import BasePreprocessor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import tomllib\n",
    "\n",
    "from mads_hackathon import datasets, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, go to the `config.toml` file and change the `dev` value to your name. Please use `firstname_lastname` format. \n",
    "In addition to that, change the `port` value to the port of your team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using http://145.38.195.42:5002 as mlfow uri\n",
      "Using alex as dev name\n"
     ]
    }
   ],
   "source": [
    "\n",
    "configfile = Path(\"config.toml\")\n",
    "with configfile.open(\"rb\") as f:\n",
    "    tomlconfig = tomllib.load(f)\n",
    "\n",
    "assert tomlconfig[\"dev\"] != \"dev\", ValueError(\"Please set dev in config.toml to your own name\")\n",
    "assert tomlconfig[\"port\"] != \"none\", ValueError(\"Please set port in config.toml to your own port\")\n",
    "uri = tomlconfig[\"mlflow_uri\"] + \":\" + tomlconfig[\"port\"]\n",
    "dev = tomlconfig[\"dev\"]\n",
    "print(f\"Using {uri} as mlfow uri\")\n",
    "print(f\"Using {dev} as dev name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadir = Path('../hackathon-data/')\n",
    "trainfile = (datadir / \"heart_big_train.parq\").resolve()\n",
    "validfile = (datadir / \"heart_big_valid.parq\").resolve()\n",
    "trainfile.exists(), validfile.exists()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the backend, if you have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    print(\"using cuda\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"using cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the 1D data into a 2D matrix with the HeartDataset2D class. See `src/mads_hackathon/datasets.py` for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixshape = (3, 48)\n",
    "traindataset = datasets.HeartDataset2D_over(trainfile, target=\"target\", shape=matrixshape)\n",
    "testdataset = datasets.HeartDataset2D(validfile, target=\"target\", shape=matrixshape)\n",
    "traindataset.to(device)\n",
    "testdataset.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how that works. \n",
    "Compare this to the 1D data from notebook `01_explore-heart.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(x))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming your tensor is named 'tensor'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m viz \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(viz, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrainbow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m x\u001b[38;5;241m.\u001b[39mshape, y\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "x, y = traindataset[0]\n",
    "print(len(x))\n",
    "# Assuming your tensor is named 'tensor'\n",
    "viz = x.squeeze().cpu().numpy()\n",
    "sns.heatmap(viz, cmap='rainbow')\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set the config, then load into a streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNConfig(matrixshape=(4, 48), batchsize=64, input_channels=1, hidden=16, kernel_size=3, maxpool=2, num_layers=1, num_classes=5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mads_hackathon.models import CNNConfig as Config\n",
    "\n",
    "config = Config(\n",
    "    matrixshape = (4,48),\n",
    "    batchsize = 64,\n",
    "    input_channels = 1,\n",
    "    hidden = 16,\n",
    "    kernel_size = 3,\n",
    "    maxpool = 2,\n",
    "    num_layers = 1,\n",
    "    num_classes = 5,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 171)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainstreamer = BaseDatastreamer(traindataset, preprocessor = BasePreprocessor(), batchsize=config.batchsize)\n",
    "teststreamer = BaseDatastreamer(testdataset, preprocessor = BasePreprocessor(), batchsize=config.batchsize)\n",
    "len(trainstreamer), len(teststreamer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 4, 48]), torch.Size([64]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trainstreamer.stream())\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load the CNN model. It uses a ConvBlock class that is a wrapper around a Conv2D and ReLU stack.\n",
    "The ConvBlock makes it easier to stack block in the CNN model, see `src/mads_hackathon/models.py` for the implementation.\n",
    "\n",
    "This is just a initial setup: please experiment with other architectures like:\n",
    "- adding ideas like resnet, googlenet, squeeze-excite, etc.\n",
    "- add additional layers like dropout, batchnorm, etc.\n",
    "- experiment with different ways to go from 4D to 2D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated matrix size: 48\n",
      "Caluclated flatten size: 768\n"
     ]
    }
   ],
   "source": [
    "from mads_hackathon.models import CNN\n",
    "model = CNN(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "CNN                                      [64, 5]                   --\n",
       "â”œâ”€ModuleList: 1-1                        --                        --\n",
       "â”‚    â””â”€ConvBlock: 2-1                    [64, 16, 4, 48]           --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-1              [64, 16, 4, 48]           2,480\n",
       "â”‚    â””â”€ConvBlock: 2-2                    [64, 16, 4, 48]           --\n",
       "â”‚    â”‚    â””â”€Sequential: 3-2              [64, 16, 4, 48]           4,640\n",
       "â”‚    â””â”€ReLU: 2-3                         [64, 16, 4, 48]           --\n",
       "â”‚    â””â”€MaxPool2d: 2-4                    [64, 16, 2, 24]           --\n",
       "â”œâ”€Sequential: 1-2                        [64, 5]                   --\n",
       "â”‚    â””â”€Flatten: 2-5                      [64, 768]                 --\n",
       "â”‚    â””â”€Linear: 2-6                       [64, 16]                  12,304\n",
       "â”‚    â””â”€ReLU: 2-7                         [64, 16]                  --\n",
       "â”‚    â””â”€Linear: 2-8                       [64, 5]                   85\n",
       "==========================================================================================\n",
       "Total params: 19,509\n",
       "Trainable params: 19,509\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 88.28\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 6.30\n",
       "Params size (MB): 0.08\n",
       "Estimated Total Size (MB): 6.43\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, input_size=(config.batchsize, 1, *config.matrixshape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And test if the model works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 5])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "yhat = model(x)\n",
    "yhat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is unbalanced, so we are interested in much more than just accuracy.\n",
    "See https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html for more information on the F1 micro/macro score.\n",
    "See `src/mads_hackathon/metrics.py` for the implementation. You might want to add more metrics, or change the settings for `average`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1scoremicro\n"
     ]
    }
   ],
   "source": [
    "f1micro = metrics.F1Score(average='micro')\n",
    "f1macro = metrics.F1Score(average='macro')\n",
    "precision = metrics.Precision(average='macro')\n",
    "recall = metrics.Recall('macro')\n",
    "accuracy = metrics.Accuracy()\n",
    "print(f1micro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want a confusion matrix to see how the model is performing on the different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_hackathon.metrics import caluclate_cfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the mlflow server to log the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/25 12:37:25 INFO mlflow.tracking.fluent: Experiment with name 'test1-alex' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/703179046667895742', creation_time=1732534645878, experiment_id='703179046667895742', last_update_time=1732534645878, lifecycle_stage='active', name='test1-alex', tags={}>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(uri)\n",
    "mlflow.set_experiment(\"test1-alex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNConfig(matrixshape=(4, 48), batchsize=64, input_channels=1, hidden=16, kernel_size=3, maxpool=2, num_layers=1, num_classes=5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config(\n",
    "    matrixshape = (4,48),\n",
    "    batchsize = 64,\n",
    "    input_channels = 1,\n",
    "    hidden = 16,\n",
    "    kernel_size = 3,\n",
    "    maxpool = 2,\n",
    "    num_layers = 1,\n",
    "    num_classes = 5,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please dont just run the cell below, but walk trough what is being logged.\n",
    "For example, you might want to change the tag for the model and the dataset if you make changes there, and \n",
    "to the scheduler/earlystop if you are using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  1.2081,  39.3855,  15.1268, 136.5897,  13.6144]),\n",
       " tensor([0.0121, 0.3939, 0.1513, 1.3659, 0.1361]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "train_df = pd.read_parquet(trainfile)\n",
    "train_percentages = train_df.target.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "weights1 = torch.tensor((100 / train_percentages).to_numpy()).float().to(device)\n",
    "weights2 = torch.tensor((1 / train_percentages).to_numpy()).float().to(device)\n",
    "\n",
    "weights1, weights2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-25 12:39:16.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.settings\u001b[0m:\u001b[36mcheck_path\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mCreated logdir /Users/alex/Desktop/advancedai/hackathon/group_c/notebooks/logs/heart2D\u001b[0m\n",
      "\u001b[32m2024-11-25 12:39:16.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mmltrainer.trainer\u001b[0m:\u001b[36mdir_add_timestamp\u001b[0m:\u001b[36m29\u001b[0m - \u001b[1mLogging to logs/heart2D/20241125-123916\u001b[0m\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/1368 [00:00<?, ?it/s]\n",
      "  0%|\u001b[38;2;30;71;6m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run wise-jay-164 at: http://145.38.195.42:5002/#/experiments/703179046667895742/runs/4f6fcde442fb4f2f84d97b42a345a8f0\n",
      "ðŸ§ª View experiment at: http://145.38.195.42:5002/#/experiments/703179046667895742\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 43\u001b[0m\n\u001b[1;32m     31\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(settings\u001b[38;5;241m.\u001b[39moptimizer_kwargs)\n\u001b[1;32m     33\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     34\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     35\u001b[0m     settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m cfm \u001b[38;5;241m=\u001b[39m caluclate_cfm(model, teststreamer)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39mdiag(cfm)):\n",
      "File \u001b[0;32m~/Desktop/advancedai/hackathon/group_c/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:90\u001b[0m, in \u001b[0;36mTrainer.loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloop\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mepochs), colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#1e4706\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 90\u001b[0m         train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m         metric_dict, test_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevalbatches()\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreport(epoch, train_loss, test_loss, metric_dict)\n",
      "File \u001b[0;32m~/Desktop/advancedai/hackathon/group_c/.venv/lib/python3.11/site-packages/mltrainer/trainer.py:124\u001b[0m, in \u001b[0;36mTrainer.trainbatches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 124\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m train_steps\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "from mltrainer import Trainer, TrainerSettings, ReportTypes\n",
    "from dataclasses import asdict\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=weights1)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    optimizer = torch.optim.Adam\n",
    "\n",
    "    settings = TrainerSettings(\n",
    "        epochs=5,\n",
    "        metrics=[accuracy, f1micro, f1macro, precision, recall],\n",
    "        logdir=\"logs/heart2D\",\n",
    "        train_steps=len(trainstreamer),\n",
    "        valid_steps=len(teststreamer),\n",
    "        reporttypes=[ReportTypes.TENSORBOARD, ReportTypes.MLFLOW],\n",
    "        scheduler_kwargs=None,\n",
    "        earlystop_kwargs=None\n",
    "    )\n",
    "\n",
    "    # modify the tags when you change them!\n",
    "    mlflow.set_tag(\"model\", \"CNN\")\n",
    "    mlflow.set_tag(\"dataset\", \"heart2D\")\n",
    "    mlflow.set_tag(\"dev\", dev)\n",
    "    mlflow.log_param(\"scheduler\", \"None\")\n",
    "    mlflow.log_param(\"earlystop\", \"None\")\n",
    "\n",
    "    mlflow.log_params(asdict(config))\n",
    "    mlflow.log_param(\"epochs\", settings.epochs)\n",
    "    mlflow.log_param(\"matrix0\", config.matrixshape[0])\n",
    "    mlflow.log_param(\"matrix1\", config.matrixshape[1])\n",
    "    mlflow.log_param(\"optimizer\", str(optimizer))\n",
    "    mlflow.log_params(settings.optimizer_kwargs)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        settings=settings,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        traindataloader=trainstreamer.stream(),\n",
    "        validdataloader=teststreamer.stream(),\n",
    "        scheduler=None,\n",
    "        device=device,\n",
    "        )\n",
    "    trainer.loop()\n",
    "    cfm = caluclate_cfm(model, teststreamer)\n",
    "    for i, tp in enumerate(np.diag(cfm)):\n",
    "        mlflow.log_metric(f\"TP_{i}\", tp)\n",
    "\n",
    "plot = sns.heatmap(cfm, annot=cfm, fmt=\".3f\")\n",
    "plot.set(xlabel=\"Predicted\", ylabel=\"Target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that, while the TP score for class 0 does get high without much effort, the challenge here will be in the other classes that lag behind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
